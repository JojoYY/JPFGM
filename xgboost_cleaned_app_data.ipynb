{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "This notebook trains different gradient boosting models on the cleaned version of the application training data and produces predictions for the application test data. The notebook is structured as follows:\n",
    "- Data preparation \n",
    "    - load cleaned and merged data\n",
    "    - create train and validation sets for model selection\n",
    "- Model selection\n",
    "    - tune hyperparameters, based on AUC and OOS performance\n",
    "    - save best model\n",
    "    - examine predictions of best model for further ideas\n",
    "- Make predictions on test set\n",
    "    - load selected model\n",
    "    - predict on test set and create submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import basic_application_data_cleaner as cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw training data size: (307511, 121)\n",
      "Raw test data size: (48744, 120)\n",
      "Cleaned training data shape:  (307511, 246)\n",
      "Cleaned testing data shape:  (48744, 245)\n"
     ]
    }
   ],
   "source": [
    "path_to_kaggle_data='~/kaggle_JPFGM/Data/'  # location of all the unzipped data files on local machine# Training data\n",
    "df_train, df_test = cleaner.load_cleaned_application_data(path_to_kaggle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the training data (with labels)\n",
    "X = df_train.drop(['TARGET'], axis=1)\n",
    "y = df_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.91927\n",
       "1    0.08073\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.919274\n",
       "1    0.080726\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: X and X_train are all still pandas dataframes, not numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines\n",
    "Note that there are several ways to implement xgboost based on different libraries. This notebook compares the output, performance and speed of different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main hyperparameters to tune:\n",
    "- It is recommended to set a small learning rate, and choose n_estimators by early stopping. warm_start: in relation with early stopping\n",
    "- max_depth: tune it, depends on the input. could be quite large for our large number of features\n",
    "- for decorrelating trees, subsample = 0.5 (train on subset of training data). Can also do that on whole df_train since can produce oob score\n",
    "- for decorrelating trees, and reducing run time, use a small max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn.ensemble.GradientBoostingClassifier\n",
    "Original sklearn module for tree boosting. Use like other sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model and get out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 184.3 seconds\n"
     ]
    }
   ],
   "source": [
    "# fit xgboost model on training data\n",
    "start = time.time()\n",
    "\n",
    "# by default fits 100 trees of max_depth 3\n",
    "gbc_clf = GradientBoostingClassifier(learning_rate=0.1, random_state=0)\n",
    "gbc_clf.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Execution time:', np.round(end - start, 1), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 75.27%\n"
     ]
    }
   ],
   "source": [
    "# model performance on validation set\n",
    "y_proba_gbc = gbc_clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "auc_gbc = roc_auc_score(y_val, y_proba_gbc)\n",
    "print(\"AUC: %.2f%%\" % (auc_gbc * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.5, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=120,\n",
       "              presort='auto', random_state=0, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose n_estimators by early stopping (train a large number of trees then find the optimal)\n",
    "# runs slow\n",
    "gbc_clf = GradientBoostingClassifier(learning_rate=0.5, n_estimators=120, random_state=0)\n",
    "gbc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_gbc_staged = [roc_auc_score(y_val, proba[:,1]) for proba in gbc_clf.staged_predict_proba(X_val)]\n",
    "bst_n_estimator = np.argmax(auc_gbc_staged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal num_estimators = 96 with validation set AUC = 75.58%\n"
     ]
    }
   ],
   "source": [
    "print('optimal num_estimators = %d with validation set AUC = %.2f%%' \n",
    "      %(bst_n_estimator, max(auc_gbc_staged)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine predictions of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.01%\n"
     ]
    }
   ],
   "source": [
    "y_pred_gbc = gbc_clf.predict(X_val)  # creates np array\n",
    "acr_gbc = accuracy_score(y_val, y_pred_gbc)\n",
    "print(\"Accuracy: %.2f%%\" % (acr_gbc * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using xgboost.XGBClassifier\n",
    "Using xgboost in our case has several advantages over sklearn's gradientboostingclassifier:\n",
    "- includes regularization\n",
    "- can output feature importance\n",
    "- well optimized for sparse data (e.g. categorical data and one-hot-encoding)\n",
    "- can do early stopping, helps a lot of kagglers\n",
    "- fastest implementation of boosting algorithms \n",
    "- can be run in distributed way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model and evaluate OOS performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 95.8 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Execution time:', np.round(end - start, 1), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 74.99%\n"
     ]
    }
   ],
   "source": [
    "# model performance on validation set\n",
    "y_proba_xgb = xgb_clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "auc_xgb = roc_auc_score(y_val, y_proba_xgb)\n",
    "print(\"AUC: %.2f%%\" % (auc_xgb * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.03%\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb_clf.predict(X_val)  # creates np array\n",
    "acr_xgb = accuracy_score(y_val, y_pred_xgb)\n",
    "print(\"Accuracy: %.2f%%\" % (acr_xgb * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune xgboost\n",
    "Parameters for XGBClassifier to set:\n",
    "- objective : use default 'binary:logistic'\n",
    "- booster: use default 'gbtree'\n",
    "- n_jobs : default 1, set higher for parallel processing\n",
    "- random_state : set a number for reproduceability\n",
    "\n",
    "Parameters for XGBClassifier to tune:\n",
    "- gamma: \n",
    "- max_depth : int, default 3\n",
    "    Maximum tree depth for base learners.\n",
    "- learning_rate : float, default 0.1\n",
    "    Boosting learning rate (xgb's \"eta\")\n",
    "- n_estimators : int, default 100\n",
    "    Number of boosted trees to fit.\n",
    "- subsample : float\n",
    "    Subsample ratio of the training instance.\n",
    "- reg_alpha : float (xgb's alpha)\n",
    "    L1 regularization term on weights\n",
    "- reg_lambda : float (xgb's lambda)\n",
    "    L2 regularization term on weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.386941622076595"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for scale positive weight\n",
    "sum(y_train==0)/sum(y_train==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 75.08%\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(scale_pos_weight=11,\n",
    "                            random_state=123)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_proba_xgb = xgb_clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "auc_xgb = roc_auc_score(y_val, y_proba_xgb)\n",
    "print(\"AUC: %.2f%%\" % (auc_xgb * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=123, reg_alpha=0, reg_lambda=1, scale_pos_weight=11,\n",
       "       seed=None, silent=True, subsample=1)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost with DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data in efficient internal data structure\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 30\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with early stopping\n",
    "num_round = 30\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "evallist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "bst = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_round, evals=evallist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select = xgb_clf\n",
    "y_submit = model_select.predict_proba(df_test)\n",
    "\n",
    "df_submit = pd.DataFrame({'SK_ID_CURR': df_test.index,\n",
    "                          'TARGET': y_submit[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.050252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.117547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.021563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.035864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.120923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.050252\n",
       "1      100005  0.117547\n",
       "2      100013  0.021563\n",
       "3      100028  0.035864\n",
       "4      100038  0.120923"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_output='baseline2_xgb.csv'\n",
    "df_submit.to_csv(filename_output, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
