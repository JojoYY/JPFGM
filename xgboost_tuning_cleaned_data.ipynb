{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost on Application data\n",
    "This notebook trains the xgboost model on the cleaned version of the application training data and produces predictions for the application test data. It is structured as follows:\n",
    "- Data preparation \n",
    "    - load cleaned and merged data\n",
    "    - create train and validation sets for model selection\n",
    "- Model selection\n",
    "    - benchmark: default model performance\n",
    "    - tune hyperparameters, based on AUC and OOS performance\n",
    "    - save best model and examine prediction errors\n",
    "- Make predictions on test set\n",
    "    - load selected model\n",
    "    - predict on test set and create submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import basic_application_data_cleaner as cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw training data size: (307511, 121)\n",
      "Raw test data size: (48744, 120)\n",
      "Cleaned training data shape:  (307511, 246)\n",
      "Cleaned testing data shape:  (48744, 245)\n"
     ]
    }
   ],
   "source": [
    "path_to_kaggle_data='~/kaggle_JPFGM/Data/'  # location of all the unzipped data files on local machine\n",
    "df_train, df_test = cleaner.load_cleaned_application_data(path_to_kaggle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the training data (with labels)\n",
    "# SK_ID is set as index in previous data cleaning\n",
    "X = df_train.drop(['TARGET'], axis=1)\n",
    "y = df_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation sets in stratified way\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.91927\n",
       "1    0.08073\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.919274\n",
       "1    0.080726\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: X and X_train are all still pandas dataframes, not numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(model, X, y, name='validation set',\n",
    "                      metric=['auc', 'accuracy']):\n",
    "    \"\"\"Predict on X and evaluate performance using labels y\"\"\"\n",
    "    print('Performance on %s:' % name)\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:,1]\n",
    "    if metric=='auc' or 'auc' in metric:\n",
    "        auc = roc_auc_score(y, y_proba)\n",
    "        print(\"AUC: %.2f%%\" % (auc * 100.0))\n",
    "    if metric=='accuracy' or 'accuracy' in metric:\n",
    "        acr = accuracy_score(y, y_pred)\n",
    "        print(\"Accuracy: %.2f%%\" % (acr * 100.0))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit default model and evaluate val set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 101.5 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Execution time:', np.round(end - start, 1), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default parameters\n",
    "xgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on validation set:\n",
      "AUC: 74.99%\n",
      "Accuracy: 91.95%\n"
     ]
    }
   ],
   "source": [
    "model_performance(xgb_clf, X_val, y_val, 'validation set');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training set:\n",
      "AUC: 75.92%\n",
      "Accuracy: 91.95%\n"
     ]
    }
   ],
   "source": [
    "model_performance(xgb_clf, X_train, y_train, 'training set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters to set as fixed:\n",
    "- n_jobs : default 1, set higher for parallel processing\n",
    "- silent : boolean, default True. Set to False if you want printed messages while running boosting.\n",
    "\n",
    "#### Hyperparameters to tune:\n",
    "- Number of trees:\n",
    "    - learning_rate : float, default 0.1. Boosting learning rate (xgb's \"eta\")\n",
    "    - n_estimators : int, default 100. Number of boosted trees to fit.\n",
    "    - Recommended to set a small learning rate, and choose n_estimators by early stopping\n",
    "- Decorrelate trees:\n",
    "    - subsample : float, default 1 Subsample ratio of the training instance.\n",
    "    - use a small max_features\n",
    "    - max_delta_step : int, default 0. Maximum delta step we allow each tree's weight estimation to be.\n",
    "    - colsample_bytree : float, default 1. Subsample ratio of columns when constructing each tree.\n",
    "    - colsample_bylevel : float, default 1. Subsample ratio of columns for each split, in each level.\n",
    "- Regularization strenghts:\n",
    "    - reg_alpha : float (xgb's alpha), default 0. L1 regularization term on weights\n",
    "    - reg_lambda : float (xgb's lambda), default 1. L2 regularization term on weights    \n",
    "\n",
    "- Individual tree properties:\n",
    "    - max_depth : int, default 3. Increase to allow more complex trees\n",
    "    - gamma: float, default 0. Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    - min_child_weight : int, default 1. Minimum sum of instance weight(hessian) needed in a child.\n",
    "- Imbalanced data:\n",
    "    - scale_pos_weight : float, default 1. Balancing of positive and negative weights.\n",
    "    - base_score, default 0.5. The initial prediction score of all instances, global bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.386941622076595"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for scale positive weight\n",
    "sum(y_train==0)/sum(y_train==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 75.08%\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(scale_pos_weight=11,\n",
    "                            random_state=123)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_proba_xgb = xgb_clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "auc_xgb = roc_auc_score(y_val, y_proba_xgb)\n",
    "print(\"AUC: %.2f%%\" % (auc_xgb * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=123, reg_alpha=0, reg_lambda=1, scale_pos_weight=11,\n",
       "       seed=None, silent=True, subsample=1)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost with DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data in efficient internal data structure\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 30\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with early stopping\n",
    "num_round = 30\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "evallist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "bst = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_round, evals=evallist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine predictions of best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions on test set for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select = xgb_clf\n",
    "y_submit = model_select.predict_proba(df_test)\n",
    "\n",
    "df_submit = pd.DataFrame({'SK_ID_CURR': df_test.index,\n",
    "                          'TARGET': y_submit[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.050252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.117547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.021563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.035864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.120923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.050252\n",
       "1      100005  0.117547\n",
       "2      100013  0.021563\n",
       "3      100028  0.035864\n",
       "4      100038  0.120923"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_output='baseline2_xgb.csv'\n",
    "#df_submit.to_csv(filename_output, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
