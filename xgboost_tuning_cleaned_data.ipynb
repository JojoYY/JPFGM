{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost on Application data\n",
    "This notebook trains the xgboost model on the cleaned version of the application training data and produces predictions for the application test data. It is structured as follows:\n",
    "- Data preparation \n",
    "    - load cleaned and merged data\n",
    "    - create train and validation sets for model selection\n",
    "- Model selection\n",
    "    - benchmark: default model performance\n",
    "    - tune hyperparameters, based on AUC and OOS performance\n",
    "    - save best model and examine prediction errors\n",
    "- Make predictions on test set\n",
    "    - load selected model\n",
    "    - predict on test set and create submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import basic_application_data_cleaner as cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw training data size: (307511, 121)\n",
      "Raw test data size: (48744, 120)\n",
      "Cleaned training data shape:  (307511, 246)\n",
      "Cleaned testing data shape:  (48744, 245)\n"
     ]
    }
   ],
   "source": [
    "path_to_kaggle_data='~/kaggle_JPFGM/Data/'  # location of all the unzipped data files on local machine\n",
    "df_train, df_test = cleaner.load_cleaned_application_data(path_to_kaggle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the training data (with labels)\n",
    "# SK_ID is set as index in previous data cleaning\n",
    "X = df_train.drop(['TARGET'], axis=1)\n",
    "y = df_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation sets in stratified way\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of positive samples in training set: 8.07%\n",
      "Fraction of positive samples in validation set: 8.07%\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of positive samples in training set: %.2f%%' % (100*sum(y_train==1)/len(y_train)))\n",
    "print('Fraction of positive samples in validation set: %.2f%%' % (100*sum(y_val==1)/len(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: X and X_train are all still pandas dataframes, not numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model_performance_metric(model, X, y, metric):\n",
    "    \"\"\"Predict on X and evaluate performance metric using labels y.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: pre-trained model.\n",
    "        Needs to have .predict() and .predict_proba() methods\n",
    "    X: np array or pandas dataframe.\n",
    "        Data to predict and evaluate model on\n",
    "    y: np array or pandas Series\n",
    "        labels to evaluate model\n",
    "    metric: string or list of strings. Supports 'auc' and 'accuracy'\n",
    "        Evaluation metrics.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:,1]\n",
    "\n",
    "    if isinstance(metric, str):\n",
    "        l_metric = [metric]\n",
    "    elif isinstance(metric, list):\n",
    "        l_metric = metric\n",
    "    else:\n",
    "        raise ValueError('metric has to be either string or list of strings')\n",
    "    scores = []\n",
    "    for metric in l_metric:\n",
    "        if metric=='auc':\n",
    "            score = roc_auc_score(y, y_proba)\n",
    "        elif metric=='accuracy':\n",
    "            score = accuracy_score(y, y_pred)\n",
    "        else:\n",
    "            raise ValueError('metric not defined')\n",
    "        scores.append(\"%.2f%%\" % (score * 100.0))\n",
    "    s_scores = pd.Series(scores, index=l_metric)\n",
    "    return s_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_train_test_split(model, X_train, X_val, y_train, y_val, metric=['auc', 'accuracy']):\n",
    "    \"\"\"Compare model performance on train and test set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: pre-trained model.\n",
    "        Needs to have .predict() and .predict_proba() methods\n",
    "    X_train, X_val: np array or pandas dataframe.\n",
    "        Data to predict and evaluate model on\n",
    "    y_train, y_val: np array or pandas Series\n",
    "        labels to evaluate model\n",
    "    metric: string or list of strings.\n",
    "        Evaluation metrics.\n",
    "    \"\"\"\n",
    "    train_scores = _model_performance_metric(model, X_train, y_train, metric)\n",
    "    val_scores = _model_performance_metric(model, X_val, y_val, metric)\n",
    "    df_scores = pd.concat([train_scores, val_scores], axis=1).rename(columns={0:'Training Set', 1:'Validation Set'})\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit default model and evaluate val set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 98.9 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgb_def = xgb.XGBClassifier()\n",
    "xgb_def.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Execution time:', np.round(end - start, 1), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default parameters\n",
    "xgb_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>75.92%</td>\n",
       "      <td>74.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>91.95%</td>\n",
       "      <td>91.95%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Training Set Validation Set\n",
       "auc            75.92%         74.99%\n",
       "accuracy       91.95%         91.95%"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance_train_test_split(xgb_def, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters to set as fixed:\n",
    "- **n_jobs** : default 1, set higher for parallel processing\n",
    "- **silent** : boolean, default True. Set to False if you want printed messages while running boosting.\n",
    "- **scale_pos_weight** : float, default 1. Control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider: sum(negative instances) / sum(positive instances)\n",
    "- **base_score**, default 0.5. The initial prediction score of all instances, global bias.\n",
    "- **eval_metric**: set as auc\n",
    "\n",
    "#### Hyperparameters to tune:\n",
    "- Number of trees:\n",
    "    - **learning_rate** : float, default 0.1. Boosting learning rate (xgb's \"eta\"). Recommended to set a small learning rate, and choose n_estimators by early stopping\n",
    "    - **n_estimators** : int, default 100. Number of boosted trees to fit. \n",
    "- Decorrelate trees:\n",
    "    - use a small max_features\n",
    "    - (max_delta_step) : int, default 0. Maximum delta step we allow each tree's weight estimation to be. Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced.\n",
    "    - **colsample_bytree**: float, default 1. Subsample ratio of columns when constructing each tree.\n",
    "    - (colsample_bylevel) : float, default 1. Subsample ratio of columns for each split, in each level.\n",
    "- Regularization strenghts (default: L2 regularization):\n",
    "    - reg_alpha : float (xgb's alpha), default 0. L1 regularization term on weights.  Increasing this value will make model more conservative.\n",
    "    - **reg_lambda** : float (xgb's lambda), default 1. L2 regularization term on weights. Increasing this value will make model more conservative.  \n",
    "    - **subsample** : float, default 1 Subsample ratio of the training instance. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting. \n",
    "- Individual tree complexity: (start with one of them)\n",
    "    - **max_depth** : int, default 3. Increase to allow more complex trees\n",
    "    - (gamma): float, default 0. Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\n",
    "    - (min_child_weight): int, default 1. Minimum sum of instance weight(hessian) needed in a child. The larger min_child_weight is, the more conservative the algorithm will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive initial prediction score: 0.0807301778365\n",
      "Negative to positive instances, for use as scale_pos_weight: 11.3869416221\n"
     ]
    }
   ],
   "source": [
    "# parameters to set for unbalanced data\n",
    "pos_proba = sum(y_train==1)/len(y_train)\n",
    "print('Naive initial prediction score:', pos_proba)\n",
    "\n",
    "pos_weight = sum(y_train==0) / sum(y_train==1)\n",
    "print('Negative to positive instances, for use as scale_pos_weight:', pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 425.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# reasonable parameter choices for not-to-tune parameters\n",
    "xgb_clf = xgb.XGBClassifier(base_score=pos_proba,\n",
    "                            scale_pos_weight=pos_weight,\n",
    "                            max_depth=6,\n",
    "                            subsample=0.8, colsample_bytree=0.8,  # decorrelate trees and faster run\n",
    "                            eval_metric = 'auc',\n",
    "                            silent=False)\n",
    "\n",
    "                           \n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Execution time:', np.round(end - start, 1), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>81.69%</td>\n",
       "      <td>75.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>72.79%</td>\n",
       "      <td>71.37%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Training Set Validation Set\n",
       "auc            81.69%         75.32%\n",
       "accuracy       72.79%         71.37%"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance_train_test_split(xgb_clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune main parameters: learning rate & number of trees, reg_lambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost with DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data in efficient internal data structure\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 30\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with early stopping\n",
    "num_round = 30\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "evallist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "bst = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_round, evals=evallist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine predictions of best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions on test set for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select = xgb_clf\n",
    "y_submit = model_select.predict_proba(df_test)\n",
    "\n",
    "df_submit = pd.DataFrame({'SK_ID_CURR': df_test.index,\n",
    "                          'TARGET': y_submit[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.050252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.117547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.021563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.035864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.120923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.050252\n",
       "1      100005  0.117547\n",
       "2      100013  0.021563\n",
       "3      100028  0.035864\n",
       "4      100038  0.120923"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_output='baseline2_xgb.csv'\n",
    "#df_submit.to_csv(filename_output, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
