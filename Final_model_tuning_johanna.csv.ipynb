{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from scipy import stats\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ponien_data(path_to_data):\n",
    "    pn_train = pd.read_csv(path_to_data + '/features_train_revised.csv', index_col='SK_ID_CURR')\n",
    "    pn_test = pd.read_csv(path_to_data + '/features_test_revised.csv', index_col='SK_ID_CURR')\n",
    "    \n",
    "    # remove infinity values\n",
    "    pn_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    pn_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        \n",
    "    # winsorize data to avoid sensitivity to outliers\n",
    "    lower = pn_train.quantile(0.005)\n",
    "    upper = pn_train.quantile(0.995)\n",
    "    pn_train.clip(lower, upper, axis=1, inplace=True)\n",
    "    pn_test.clip(lower, upper, axis=1, inplace=True)\n",
    "    \n",
    "    # missing data flag\n",
    "    if np.any(np.isnan(pn_train)) or np.any(np.isnan(pn_test)):\n",
    "        print('Missing data in train or test set')\n",
    "    else:\n",
    "        print('No missing data')\n",
    "    \n",
    "    print('training data size:', pn_train.shape)\n",
    "    print('test data size:', pn_test.shape)\n",
    "    return pn_train, pn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ks_scores(df_train):\n",
    "    # For a training data set with binary labels, compute ks scores for each feature\n",
    "    goods = df_train.query('TARGET == 0')\n",
    "    defaults = df_train.query('TARGET == 1')\n",
    "\n",
    "    start = time.time()\n",
    "    variables = np.array([])\n",
    "    scores = np.array([])\n",
    "    for v in df_train.columns:\n",
    "        variable = v\n",
    "        ks = stats.ks_2samp(goods[v], defaults[v])\n",
    "        variables = np.hstack((variables,v))\n",
    "        scores = np.hstack((scores,ks[0]))  # large K-S statistic -> distributions different\n",
    "    end = time.time() \n",
    "    print('time elapsed: {:.2f}'.format(end-start))\n",
    "    return pd.Series(scores, index=variables)\n",
    "\n",
    "def train_test_top_ks(train_data, test_data, ks_scores, top_num):\n",
    "    # creates subsets of train and test data sets by selecting features according to KS statistic\n",
    "    top_features = list(ks_scores.sort_values(ascending=False).index[1:top_num+1]) # 0 is TARGET\n",
    "    \n",
    "    df_train = train_data.copy()[top_features + ['TARGET']]\n",
    "    df_test = test_data.copy()[top_features]\n",
    "    print('training data size:', df_train.shape)\n",
    "    print('test data size:', df_test.shape)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_cols_impute_median(train_data, test_data, pct_threshold=100):\n",
    "    proc_train = train_data.copy()  # to avoid overwriting original data\n",
    "    proc_test = test_data.copy()\n",
    "    \n",
    "    # drop columns with too many missing values\n",
    "    pct_missing = np.round(100*proc_train.isnull().sum()/len(proc_train), 1)\n",
    "    col_missing = list(pct_missing[pct_missing>pct_threshold].index)\n",
    "    \n",
    "    print('deleting %d columns with %d%% or more missing data (in training set)' %(len(col_missing), pct_threshold))\n",
    "    \n",
    "    proc_train.drop(columns=col_missing, inplace=True)  # copy necessary otherwise original data altered!\n",
    "    proc_test.drop(columns=col_missing, inplace=True)\n",
    "    del pct_missing, col_missing\n",
    "    gc.collect()\n",
    "    \n",
    "    # impute remaining missing data with median\n",
    "    feature_cols = list(proc_train.columns)\n",
    "    feature_cols.remove('TARGET')\n",
    "\n",
    "    imputer = Imputer(strategy='median')\n",
    "    proc_train[feature_cols]= imputer.fit_transform(proc_train[feature_cols])\n",
    "    proc_test[feature_cols] = imputer.transform(proc_test[feature_cols])  # need subsetting, otherwise output is array\n",
    "    print('new training data shape:', proc_train.shape)\n",
    "    print('new test data shape:', proc_test.shape)\n",
    "\n",
    "    # sanity checks    \n",
    "    if np.any(np.isnan(proc_train[feature_cols])):\n",
    "        raise ValueError('Missing values in new training data')\n",
    "    elif np.any(np.isnan(proc_test[feature_cols])):\n",
    "        raise ValueError('Missing values in new test data')\n",
    "    \n",
    "    return proc_train, proc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_val_set(train_data, frac_eval):\n",
    "    \"\"\"Create separate training and testing features and labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: pandas dataframe with 'TARGET' column and feature columns (and SK_ID index)\n",
    "    frac_eval: between 0 and 1. Fraction of data to be split for evaluation\n",
    "    \"\"\"\n",
    "    X = train_data.drop(['TARGET'], axis=1)\n",
    "    y = train_data['TARGET']\n",
    "    \n",
    "    # Create train and validation sets in stratified way\n",
    "    print('Creating training and validation dataframes:')\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=frac_eval, stratify=y, random_state=42)\n",
    "    print('\\ttraining data size:', X_train.shape)\n",
    "    print('\\tvalidation data size:', X_val.shape)\n",
    "    print('\\tpositive labels in training data: %.4f%%' % (100*sum(y_train==1)/len(y_train)))\n",
    "    print('\\tpositive labels in validation data: %.4f%%' % (100*sum(y_val==1)/len(y_val)))\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(train_df, test_df, num_folds, stratified = False, debug= False):\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 100, early_stopping_rounds= 200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances01.png')\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "def main(train_df, test_df,debug=False):\n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        feat_importance = kfold_lightgbm(train_df, test_df, num_folds= 5, stratified= False, debug= debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinity values removed from train and test data\n"
     ]
    }
   ],
   "source": [
    "path_to_kaggle_data='~/kaggle_JPFGM/Data/'\n",
    "pn_train, pn_test = load_ponien_data(path_to_kaggle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 35.31\n"
     ]
    }
   ],
   "source": [
    "pn_train_ks_scores = get_ks_scores(pn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET                                                 1.000000\n",
       "NEW_EXT_SOURCES_MEAN                                   0.323893\n",
       "NEW_EXT_SOURCES_MEAN * num_earlypay_all_normalized     0.274700\n",
       "NEW_EXT_SOURCES_MEAN * num_earlypay_1000_normalized    0.256786\n",
       "EXT_SOURCE_2                                           0.223289\n",
       "EXT_SOURCE_3                                           0.197463\n",
       "BURO_DAYS_CREDIT_MEAN                                  0.154662\n",
       "NEW_EXT_SOURCES_MEAN / num_latepay_all_normalized      0.149493\n",
       "NEW_EXT_SOURCES_MEAN / num_latepay_1000_normalized     0.141983\n",
       "BURO_DAYS_CREDIT_UPDATE_MEAN                           0.137266\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_train_ks_scores.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: (307507, 601)\n",
      "test data size: (48744, 600)\n"
     ]
    }
   ],
   "source": [
    "ks_train_600, ks_test_600 = train_test_top_ks(pn_train, pn_test, pn_train_ks_scores, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting 203 columns with 60% or more missing data (in training set)\n",
      "new training data shape: (307507, 398)\n",
      "new test data shape: (48744, 397)\n"
     ]
    }
   ],
   "source": [
    "lr_train, lr_test = drop_cols_impute_median(ks_train_600, ks_test_600, pct_threshold=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "feature_cols = list(lr_test.columns)\n",
    "lr_train[feature_cols]= scaler.fit_transform(lr_train[feature_cols])  # so that output is dataframe\n",
    "lr_test[feature_cols]= scaler.transform(lr_test[feature_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training and validation dataframes:\n",
      "\ttraining data size: (246005, 397)\n",
      "\tvalidation data size: (61502, 397)\n",
      "\tpositive labels in training data: 8.0730%\n",
      "\tpositive labels in validation data: 8.0729%\n"
     ]
    }
   ],
   "source": [
    "# Create train and validation set for model evaluation\n",
    "X_train, X_val, y_train, y_val = create_train_val_set(lr_train, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.773441605966637"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation on val set, with faster solver\n",
    "log_reg = LogisticRegression(penalty='l1', C=0.01, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_predproba = log_reg.predict_proba(X_val)[:,1]\n",
    "roc_auc_score(y_val, y_predproba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM 5 fold 600 features\n",
    "Feature pre-selection according to KS statistic. Numeric features, with NA and inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307507, 600), test shape: (48744, 599)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.776238\tvalid_1's auc: 0.764735\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-7b36cd1e5b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmission_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"submission_0828_600.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Full model run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mks_train_600\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mks_test_600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-3ebc06854fda>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_df, test_df, debug)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run LightGBM with kfold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mfeat_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_lightgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-7611e51a0494>\u001b[0m in \u001b[0;36mkfold_lightgbm\u001b[0;34m(train_df, test_df, num_folds, stratified, debug)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n\u001b[0;32m---> 38\u001b[0;31m             eval_metric= 'auc', verbose= 100, early_stopping_rounds= 200)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moof_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johanna/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johanna/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johanna/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johanna/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "submission_file_name = \"submission_0828_600.csv\"\n",
    "with timer(\"Full model run\"):\n",
    "    main(train_df=ks_train_600 , test_df=ks_test_600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
