{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM on Application data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import basic_application_data_cleaner as cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_kaggle_data='~/kaggle_JPFGM/Data/'  # location of all the unzipped data files on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw training data size: (307511, 121)\n",
      "Raw test data size: (48744, 120)\n",
      "Raw training data size: (307511, 121)\n",
      "Raw test data size: (48744, 120)\n",
      "Cleaned training data shape:  (307511, 246)\n",
      "Cleaned testing data shape:  (48744, 245)\n"
     ]
    }
   ],
   "source": [
    "# TODO: make LightGBM work with raw categorical data\n",
    "app_train, app_test = cleaner.read_raw_application_data(path_to_kaggle_data)\n",
    "\n",
    "df_train, df_test = cleaner.load_cleaned_application_data(path_to_kaggle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the training data (with labels)\n",
    "# SK_ID is set as index in previous data cleaning\n",
    "X = df_train.drop(['TARGET'], axis=1)\n",
    "y = df_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation sets in stratified way\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of positive samples in training set: 8.07%\n",
      "Fraction of positive samples in validation set: 8.07%\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of positive samples in training set: %.2f%%' % (100*sum(y_train==1)/len(y_train)))\n",
    "print('Fraction of positive samples in validation set: %.2f%%' % (100*sum(y_val==1)/len(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: X and X_train are all still pandas dataframes, not numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default LightGBM on cleaned training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, y_train)\n",
    "val_data = lgb.Dataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves':31, 'num_trees':100, 'objective':'binary'}\n",
    "param['metric'] = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.707732\n",
      "[2]\tvalid_0's auc: 0.712091\n",
      "[3]\tvalid_0's auc: 0.716871\n",
      "[4]\tvalid_0's auc: 0.71983\n",
      "[5]\tvalid_0's auc: 0.721601\n",
      "[6]\tvalid_0's auc: 0.723919\n",
      "[7]\tvalid_0's auc: 0.726027\n",
      "[8]\tvalid_0's auc: 0.7272\n",
      "[9]\tvalid_0's auc: 0.728626\n",
      "[10]\tvalid_0's auc: 0.729757\n",
      "[11]\tvalid_0's auc: 0.731393\n",
      "[12]\tvalid_0's auc: 0.732719\n",
      "[13]\tvalid_0's auc: 0.733883\n",
      "[14]\tvalid_0's auc: 0.73548\n",
      "[15]\tvalid_0's auc: 0.736782\n",
      "[16]\tvalid_0's auc: 0.737646\n",
      "[17]\tvalid_0's auc: 0.738194\n",
      "[18]\tvalid_0's auc: 0.739336\n",
      "[19]\tvalid_0's auc: 0.740335\n",
      "[20]\tvalid_0's auc: 0.741024\n",
      "[21]\tvalid_0's auc: 0.741787\n",
      "[22]\tvalid_0's auc: 0.7424\n",
      "[23]\tvalid_0's auc: 0.743238\n",
      "[24]\tvalid_0's auc: 0.743712\n",
      "[25]\tvalid_0's auc: 0.744473\n",
      "[26]\tvalid_0's auc: 0.744921\n",
      "[27]\tvalid_0's auc: 0.745509\n",
      "[28]\tvalid_0's auc: 0.746039\n",
      "[29]\tvalid_0's auc: 0.746558\n",
      "[30]\tvalid_0's auc: 0.747359\n",
      "[31]\tvalid_0's auc: 0.747914\n",
      "[32]\tvalid_0's auc: 0.748438\n",
      "[33]\tvalid_0's auc: 0.748822\n",
      "[34]\tvalid_0's auc: 0.749129\n",
      "[35]\tvalid_0's auc: 0.749261\n",
      "[36]\tvalid_0's auc: 0.749483\n",
      "[37]\tvalid_0's auc: 0.750019\n",
      "[38]\tvalid_0's auc: 0.750477\n",
      "[39]\tvalid_0's auc: 0.750731\n",
      "[40]\tvalid_0's auc: 0.751042\n",
      "[41]\tvalid_0's auc: 0.751279\n",
      "[42]\tvalid_0's auc: 0.751482\n",
      "[43]\tvalid_0's auc: 0.75163\n",
      "[44]\tvalid_0's auc: 0.751717\n",
      "[45]\tvalid_0's auc: 0.751995\n",
      "[46]\tvalid_0's auc: 0.7523\n",
      "[47]\tvalid_0's auc: 0.752762\n",
      "[48]\tvalid_0's auc: 0.752861\n",
      "[49]\tvalid_0's auc: 0.753039\n",
      "[50]\tvalid_0's auc: 0.753098\n",
      "[51]\tvalid_0's auc: 0.753306\n",
      "[52]\tvalid_0's auc: 0.753452\n",
      "[53]\tvalid_0's auc: 0.753684\n",
      "[54]\tvalid_0's auc: 0.754018\n",
      "[55]\tvalid_0's auc: 0.754247\n",
      "[56]\tvalid_0's auc: 0.754318\n",
      "[57]\tvalid_0's auc: 0.754379\n",
      "[58]\tvalid_0's auc: 0.754449\n",
      "[59]\tvalid_0's auc: 0.754508\n",
      "[60]\tvalid_0's auc: 0.75451\n",
      "[61]\tvalid_0's auc: 0.754783\n",
      "[62]\tvalid_0's auc: 0.754922\n",
      "[63]\tvalid_0's auc: 0.754931\n",
      "[64]\tvalid_0's auc: 0.755093\n",
      "[65]\tvalid_0's auc: 0.755228\n",
      "[66]\tvalid_0's auc: 0.755195\n",
      "[67]\tvalid_0's auc: 0.755193\n",
      "[68]\tvalid_0's auc: 0.755243\n",
      "[69]\tvalid_0's auc: 0.755235\n",
      "[70]\tvalid_0's auc: 0.755269\n",
      "[71]\tvalid_0's auc: 0.755268\n",
      "[72]\tvalid_0's auc: 0.755353\n",
      "[73]\tvalid_0's auc: 0.755451\n",
      "[74]\tvalid_0's auc: 0.7554\n",
      "[75]\tvalid_0's auc: 0.7554\n",
      "[76]\tvalid_0's auc: 0.75555\n",
      "[77]\tvalid_0's auc: 0.75556\n",
      "[78]\tvalid_0's auc: 0.755638\n",
      "[79]\tvalid_0's auc: 0.755608\n",
      "[80]\tvalid_0's auc: 0.755758\n",
      "[81]\tvalid_0's auc: 0.755885\n",
      "[82]\tvalid_0's auc: 0.755935\n",
      "[83]\tvalid_0's auc: 0.755941\n",
      "[84]\tvalid_0's auc: 0.756035\n",
      "[85]\tvalid_0's auc: 0.755961\n",
      "[86]\tvalid_0's auc: 0.755974\n",
      "[87]\tvalid_0's auc: 0.756153\n",
      "[88]\tvalid_0's auc: 0.756121\n",
      "[89]\tvalid_0's auc: 0.756108\n",
      "[90]\tvalid_0's auc: 0.756116\n",
      "[91]\tvalid_0's auc: 0.756029\n",
      "[92]\tvalid_0's auc: 0.755972\n",
      "[93]\tvalid_0's auc: 0.755997\n",
      "[94]\tvalid_0's auc: 0.755992\n",
      "[95]\tvalid_0's auc: 0.756039\n",
      "[96]\tvalid_0's auc: 0.756061\n",
      "[97]\tvalid_0's auc: 0.756141\n",
      "[98]\tvalid_0's auc: 0.756219\n",
      "[99]\tvalid_0's auc: 0.756279\n",
      "[100]\tvalid_0's auc: 0.756237\n"
     ]
    }
   ],
   "source": [
    "num_round = 100\n",
    "bst = lgb.train(param, train_data, num_round, valid_sets=[val_data]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.Booster(model_file='model.txt')  #init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bst.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no predict_proba!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
